{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from sklearn.svm import LinearSVC\n",
    "from collections import defaultdict\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 73)\n",
      "(40000, 73)\n"
     ]
    }
   ],
   "source": [
    "train_data = np.loadtxt(\"train.dat\")\n",
    "test_data = np.loadtxt(\"test.dat\")\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 1.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 64)\n"
     ]
    }
   ],
   "source": [
    "X = train_data[:,0:64]\n",
    "muxinput1 = train_data[:,64:68]\n",
    "muxinput2 = train_data[:,68:72]\n",
    "y = train_data[:,72]\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 13, 0)\n",
      "time: 0.00020080000012967503 seconds\n",
      "0\n",
      "time: 0.00011769999991884106 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def compare1(a,b):\n",
    "    n1 = 1*a[0] + 2*a[1] + 4*a[2] + 8*a[3]\n",
    "    n2 = 1*b[0] + 2*b[1] + 4*b[2] + 8*b[3]\n",
    "\n",
    "    res = 1 if n1 > n2 else 0\n",
    "    return (n1, n2, res)\n",
    "\n",
    "def compare2(a, b):\n",
    "    x_0 = a[0]*b[0] + (1-a[0])*(1-b[0])\n",
    "    x_1 = a[1]*b[1] + (1-a[1])*(1-b[1])\n",
    "    x_2 = a[2]*b[2] + (1-a[2])*(1-b[2])\n",
    "    x_3 = a[3]*b[3] + (1-a[3])*(1-b[3])\n",
    "\n",
    "    greater = 1 if (a[3]*(1-b[3]) + x_3*a[2]*(1-b[2]) + x_3*x_2*a[1]*(1-b[1]) + x_3*x_2*x_1*a[0]*(1-b[0])) else 0\n",
    "    return greater\n",
    "    \n",
    "s1 = time.perf_counter()\n",
    "print(compare1([0,0,1,1],[1,0,1,1]))\n",
    "e1 = time.perf_counter()\n",
    "print(\"time: {} seconds\".format(e1-s1))\n",
    "s2 = time.perf_counter()\n",
    "print(compare2([0,0,1,1],[1,0,1,1]))\n",
    "e2 = time.perf_counter()\n",
    "print(\"time: {} seconds\".format(e2-s2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6392156862745098\n",
      "0.6746031746031746\n",
      "0.6415094339622641\n",
      "0.6287425149700598\n",
      "0.654368932038835\n",
      "0.6646216768916156\n",
      "0.6385068762278978\n",
      "0.6673866090712743\n",
      "0.662\n",
      "0.6626506024096386\n",
      "0.6550308008213552\n",
      "0.6455445544554456\n",
      "0.6292585170340681\n",
      "0.6633064516129032\n",
      "0.6646090534979424\n",
      "0.6421471172962226\n",
      "0.6489151873767258\n",
      "0.6174757281553398\n",
      "0.6633266533066132\n",
      "0.6408163265306123\n",
      "0.6129707112970711\n",
      "0.6767241379310345\n",
      "0.6388888888888888\n",
      "0.6340508806262231\n",
      "0.6293436293436293\n",
      "0.6612244897959184\n",
      "0.64\n",
      "0.6544715447154471\n",
      "0.6268939393939394\n",
      "0.630648330058939\n",
      "0.6522633744855967\n",
      "0.6343692870201096\n",
      "0.6666666666666666\n",
      "0.6588693957115009\n",
      "0.6626984126984127\n",
      "0.6477732793522267\n",
      "0.6413662239089184\n",
      "0.6816326530612244\n",
      "0.6348314606741573\n",
      "0.6458333333333334\n",
      "0.6288032454361054\n",
      "0.6194174757281553\n",
      "0.6633663366336634\n",
      "0.6300813008130082\n",
      "0.6545454545454545\n",
      "0.6475409836065574\n",
      "0.6765327695560254\n",
      "0.6149532710280374\n",
      "0.6539923954372624\n",
      "0.6530612244897959\n",
      "0.615678776290631\n",
      "0.6025369978858351\n",
      "0.6379647749510763\n",
      "0.6673228346456693\n",
      "0.6474226804123712\n",
      "0.630188679245283\n",
      "0.683495145631068\n",
      "0.6943866943866944\n",
      "0.6392785571142284\n",
      "0.6386404293381037\n",
      "0.6443514644351465\n",
      "0.6372549019607843\n",
      "0.6022304832713755\n",
      "0.6133603238866396\n",
      "0.6232179226069247\n",
      "0.6333973128598849\n",
      "0.6705426356589147\n",
      "0.5991379310344828\n",
      "0.6443089430894309\n",
      "0.676\n",
      "0.6216216216216216\n",
      "0.6619433198380567\n",
      "0.6283018867924528\n",
      "0.6365546218487395\n",
      "0.6673387096774194\n",
      "0.6580882352941176\n",
      "0.6568627450980392\n",
      "0.6632231404958677\n",
      "0.616\n",
      "0.6365638766519823\n",
      "0.6424116424116424\n",
      "0.6484848484848484\n",
      "0.6452991452991453\n",
      "0.6417004048582996\n",
      "0.6381709741550696\n",
      "0.668\n",
      "0.6746203904555315\n",
      "0.6540880503144654\n",
      "0.6240157480314961\n",
      "0.6471774193548387\n",
      "0.6707070707070707\n",
      "0.6592592592592592\n",
      "0.6475247524752475\n",
      "0.6287425149700598\n",
      "0.6255060728744939\n",
      "0.6415478615071283\n",
      "0.6500956022944551\n",
      "0.6222664015904572\n",
      "0.6716417910447762\n",
      "0.6576200417536534\n",
      "0.6710816777041942\n",
      "0.6595330739299611\n",
      "0.6442516268980477\n",
      "0.6294820717131474\n",
      "0.6275229357798165\n",
      "0.6592292089249493\n",
      "0.6306818181818182\n",
      "0.6441048034934498\n",
      "0.6620825147347741\n",
      "0.6422413793103449\n",
      "0.6687763713080169\n",
      "0.6637931034482759\n",
      "0.6616379310344828\n",
      "0.6526717557251909\n",
      "0.6341463414634146\n",
      "0.666\n",
      "0.6561922365988909\n",
      "0.6672932330827067\n",
      "0.6414728682170543\n",
      "0.6881287726358148\n",
      "time: 2.0575857162475586 seconds\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(C = 1000, fit_intercept = True, solver=\"newton-cg\", verbose = False) \n",
    "groups = defaultdict(list)\n",
    "outputs = defaultdict(list)\n",
    "models = defaultdict(list)\n",
    "labels = []\n",
    "data = []\n",
    "\n",
    "st = time.time()\n",
    "\n",
    "for e in train_data:\n",
    "    firstSbits = e[64:68]\n",
    "    lastSbits = e[68:72]\n",
    "    labels.append(e[72])\n",
    "    data.append(e[0:64])\n",
    "    i, j, flag = compare1(firstSbits, lastSbits)\n",
    "    m1 = min(int(i), int(j))\n",
    "    m2 = max(int(i), int(j))\n",
    "    groups[\"{}->{}\".format(m1, m2)].append(e[0:64])\n",
    "    outputs[\"{}->{}\".format(m1, m2)].append(e[72])\n",
    "    models[\"{}->{}\".format(m1, m2)] = model\n",
    "    \n",
    "for key in groups.keys():\n",
    "    i = np.array(groups[key])\n",
    "    o = np.array(outputs[key])\n",
    "    models[key].fit(i,o)\n",
    "    print(models[key].score(i,o))\n",
    "\n",
    "et = time.time()\n",
    "print(\"time: {} seconds\".format(et-st))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0,\n",
       " 'class_weight': None,\n",
       " 'dual': False,\n",
       " 'fit_intercept': True,\n",
       " 'intercept_scaling': 1,\n",
       " 'l1_ratio': None,\n",
       " 'max_iter': 100,\n",
       " 'multi_class': 'auto',\n",
       " 'n_jobs': None,\n",
       " 'penalty': 'l2',\n",
       " 'random_state': None,\n",
       " 'solver': 'lbfgs',\n",
       " 'tol': 0.0001,\n",
       " 'verbose': False,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models[\"1->2\"].get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5427728613569321\n",
      "0.49014084507042255\n",
      "0.5072886297376094\n",
      "0.49700598802395207\n",
      "0.5086705202312138\n",
      "0.4921135646687697\n",
      "0.49201277955271566\n",
      "0.5068493150684932\n",
      "0.49570200573065903\n",
      "0.4672897196261682\n",
      "0.4940119760479042\n",
      "0.5\n",
      "0.4984520123839009\n",
      "0.5156695156695157\n",
      "0.5286624203821656\n",
      "0.5030674846625767\n",
      "0.4954128440366973\n",
      "0.47468354430379744\n",
      "0.5432098765432098\n",
      "0.5275080906148867\n",
      "0.49732620320855614\n",
      "0.4350453172205438\n",
      "0.5046153846153846\n",
      "0.4702194357366771\n",
      "0.4389438943894389\n",
      "0.5283582089552239\n",
      "0.5290697674418605\n",
      "0.4645161290322581\n",
      "0.5366568914956011\n",
      "0.49244712990936557\n",
      "0.49216300940438873\n",
      "0.5075528700906344\n",
      "0.5174418604651163\n",
      "0.47277936962750716\n",
      "0.525\n",
      "0.48534201954397393\n",
      "0.49560117302052786\n",
      "0.5274390243902439\n",
      "0.5029411764705882\n",
      "0.49318801089918257\n",
      "0.47619047619047616\n",
      "0.43730886850152906\n",
      "0.47988505747126436\n",
      "0.4691011235955056\n",
      "0.5521472392638037\n",
      "0.47041420118343197\n",
      "0.4539877300613497\n",
      "0.5073746312684366\n",
      "0.5245398773006135\n",
      "0.5177111716621253\n",
      "0.49085365853658536\n",
      "0.47368421052631576\n",
      "0.5440729483282675\n",
      "0.4332344213649852\n",
      "0.5\n",
      "0.5029585798816568\n",
      "0.5525525525525525\n",
      "0.5340599455040872\n",
      "0.5060240963855421\n",
      "0.4847560975609756\n",
      "0.4690265486725664\n",
      "0.49127906976744184\n",
      "0.546583850931677\n",
      "0.47352941176470587\n",
      "0.504225352112676\n",
      "0.47674418604651164\n",
      "0.5162337662337663\n",
      "0.48546511627906974\n",
      "0.44857142857142857\n",
      "0.5165165165165165\n",
      "0.5210843373493976\n",
      "0.5084745762711864\n",
      "0.5227272727272727\n",
      "0.5186335403726708\n",
      "0.47634069400630913\n",
      "0.5228758169934641\n",
      "0.4838709677419355\n",
      "0.5129032258064516\n",
      "0.49096385542168675\n",
      "0.46130952380952384\n",
      "0.4808259587020649\n",
      "0.5223880597014925\n",
      "0.5147058823529411\n",
      "0.5381944444444444\n",
      "0.48467966573816157\n",
      "0.48520710059171596\n",
      "0.5061349693251533\n",
      "0.5116279069767442\n",
      "0.48286604361370716\n",
      "0.5294117647058824\n",
      "0.46688741721854304\n",
      "0.48881789137380194\n",
      "0.5344352617079889\n",
      "0.53125\n",
      "0.47151898734177217\n",
      "0.4561933534743202\n",
      "0.5426829268292683\n",
      "0.5271084337349398\n",
      "0.5111111111111111\n",
      "0.4820936639118457\n",
      "0.47988505747126436\n",
      "0.5\n",
      "0.4892966360856269\n",
      "0.5077319587628866\n",
      "0.4746268656716418\n",
      "0.4819277108433735\n",
      "0.5157593123209169\n",
      "0.5062111801242236\n",
      "0.4622093023255814\n",
      "0.4720670391061452\n",
      "0.4967948717948718\n",
      "0.4954128440366973\n",
      "0.509493670886076\n",
      "0.523972602739726\n",
      "0.5235294117647059\n",
      "0.46788990825688076\n",
      "0.5171339563862928\n",
      "0.5083333333333333\n",
      "0.4897360703812317\n",
      "0.5087719298245614\n"
     ]
    }
   ],
   "source": [
    "st = time.time()\n",
    "\n",
    "testgroups = defaultdict(list)\n",
    "testoutputs = defaultdict(list)\n",
    "\n",
    "for e in test_data:\n",
    "    firstSbits = e[64:68]\n",
    "    lastSbits = e[68:72]\n",
    "    labels.append(e[72])\n",
    "    data.append(e[0:64])\n",
    "    i, j, flag = compare1(firstSbits, lastSbits)\n",
    "    m1 = min(int(i), int(j))\n",
    "    m2 = max(int(i), int(j))\n",
    "    testgroups[\"{}->{}\".format(m1, m2)].append(e[0:64])\n",
    "    testoutputs[\"{}->{}\".format(m1, m2)].append(e[72])\n",
    "\n",
    "for key in groups.keys():\n",
    "    i = np.array(testgroups[key])\n",
    "    o = np.array(testoutputs[key])\n",
    "    # models[key].fit(i,o)\n",
    "    print(models[key].score(i,o))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
